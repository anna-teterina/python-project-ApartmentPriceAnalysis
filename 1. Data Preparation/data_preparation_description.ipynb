{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file step by step are described the transformations of the data made in the files:\n",
    "* pipeline_pre-processing.py\n",
    "* pipeline_for_training_data.ipynb\n",
    "* model-building.ipynb\n",
    "* pipeline_for_production.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import geocoder\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "import joblib\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=False)\n",
    "\n",
    "work_dir = r'C:\\Users\\User\\Desktop\\python-project-ApartmentPriceAnalysis'\n",
    "os.chdir(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_initial = pd.read_csv('data_2024-01.csv', index_col=0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data description\n",
    "The data includes the following information:\n",
    "1. **link** - link to the ad\n",
    "2. **price** - the price in PLN given in the ad or \"Zapytaj o cenę\" (\"Ask price\") in case of no price given\n",
    "3. **address** - the addres given in the ad\n",
    "4. **area** - apartment area in m²\n",
    "5. **num_rooms** - number of rooms in the apartment\n",
    "6. **floor** - the floor on which the apartment is located, usually given in the form of floor by the number of floors in the entire building, for example, 1/7\n",
    "7. **rent** - monthly rent value in PLN\n",
    "8. **ownership_status** - form of ownership of the apartment, in Poland there are full ownership, cooperative ownership right to premises, cooperative tenant right to premises and right to municipal premises\n",
    "9. **flat_condition** - condition of the apartment (to be moved in/to be finished/to be renovated)\n",
    "10. **perks** - information whether the apartment has a balcony, garden or terrace\n",
    "11. **parking** - whether the apartment has parking space\n",
    "12. **heating** - type of heating of the apartment (municipal/gas/electric/boiler room/tiled stoves/other)\n",
    "13. **market** - primary or secondary market\n",
    "14. **ad_type** - advertiser type (real estate office/developer/private)\n",
    "15. **availability** - date from when the apartment is available\n",
    "16. **year** - year of building\n",
    "17. **devel_type** - building type (Apartment block/Condominium/Townhouse/Row house etc.)\n",
    "18. **windows** - material of windows in the apartment(plastic/wooden/aluminum)\n",
    "19. **lift** - whether the apartment building has an elevator\n",
    "20. **mater** - apartment building material (brick/hollow block/silicate/large slab etc.)\n",
    "21. **utilities** - whether the apartment has Internet, cable TV, telephone\n",
    "22. **security** - whether the apartment has intercom, video intercom, territory monitoring etc.\n",
    "23. **equipment** - whether the apartment has dishwasher, refrigerator, furniture, oven etc.\n",
    "24. **add_inf** - additional information, for example, whether the apartment has air conditioning, basement, separate kitchen etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data are marked with \"Zapytaj o cenę\" (\"Ask price\"), \"Zapytaj\" (\"Ask\") and \"brak informacji\" (\"no information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing data transformation\n",
    "Used in file: **pipeline_pre-processing.py**<br>\n",
    "In the file above, a function with data preprocessing is defined.<br>\n",
    "It consists of such functions as:\n",
    "1. **standardize_missing_values**\n",
    "2. **clean_numeric_columns**\n",
    "3. **categorize_rent**\n",
    "4. **process_floor_data**\n",
    "5. **fill_missing_categoricals**\n",
    "6. **encode_parking_presence**\n",
    "7. **convert_year_to_int**\n",
    "8. **standardize_ownership_labels**\n",
    "9. **multiple_choice_transform**\n",
    "10. **location_transform**\n",
    "11. **city_info_transform**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardize_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_missing_values(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Replaces custom placeholders for missing values with standard NaN values.\n",
    "\n",
    "    This function searches the DataFrame for specific strings that are used\n",
    "    to indicate missing or unavailable information (e.g., 'Zapytaj o cenę',\n",
    "    'Zapytaj', 'brak informacji') and replaces them with `np.NaN`, which is\n",
    "    the standard missing value marker in pandas.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The input DataFrame to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with specified placeholder values replaced by NaN.\n",
    "    \"\"\"\n",
    "    missing_placeholders = [\n",
    "        'Zapytaj o cenę', # 'Ask price'\n",
    "        'Zapytaj',        # 'Ask'\n",
    "        'brak informacji' # 'no information'\n",
    "        ]\n",
    "    \n",
    "    return data.replace(missing_placeholders, np.NaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  missing_count  missing_percent\n",
      "availability              38287            81.84\n",
      "equipment                 32486            69.44\n",
      "rent                      25514            54.54\n",
      "utilities                 21380            45.70\n",
      "parking                   20529            43.88\n",
      "add_inf                   19672            42.05\n",
      "windows                   16767            35.84\n",
      "mater                     16710            35.72\n",
      "security                  14992            32.05\n",
      "perks                     10959            23.43\n",
      "ownership_status           8158            17.44\n",
      "flat_condition             7465            15.96\n",
      "heating                    6028            12.89\n",
      "price                      2109             4.51\n",
      "floor                       751             1.61\n",
      "year                         26             0.06\n",
      "devel_type                    9             0.02\n",
      "lift                          0             0.00\n",
      "link                          0             0.00\n",
      "ad_type                       0             0.00\n",
      "num_rooms                     0             0.00\n",
      "area                          0             0.00\n",
      "address                       0             0.00\n",
      "market                        0             0.00\n"
     ]
    }
   ],
   "source": [
    "standardized_missing_values_data = standardize_missing_values(data_initial)\n",
    "\n",
    "missing_info = (\n",
    "    standardized_missing_values_data.isna()\n",
    "    .sum()\n",
    "    .to_frame(name='missing_count')\n",
    "    .assign(\n",
    "        missing_percent=lambda df: round(100 * df['missing_count'] / len(standardized_missing_values_data), 2)\n",
    "    )\n",
    "    .sort_values(by='missing_count', ascending=False)\n",
    ")\n",
    "\n",
    "print(missing_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean_numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric_columns(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cleans and converts specified columns containing numeric values with extra characters to float type.\n",
    "\n",
    "    This function is designed to process the columns \"price\", \"area\", and \"rent\" in a DataFrame\n",
    "    where numeric values may be represented as strings containing non-numeric characters such as\n",
    "    units (e.g., \"m²\"), letters, or whitespace. The steps include:\n",
    "\n",
    "    1. Converting each value to string format to enable regex processing.\n",
    "    2. Removing all alphabetic characters (including Polish-specific letters like 'ł', 'Ł', '²') and spaces.\n",
    "    3. Replacing commas with dots to correctly format decimal numbers.\n",
    "    4. Converting cleaned strings to numeric (float) values using `pd.to_numeric`.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The input DataFrame that contains the columns \"price\", \"area\", and \"rent\".\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The modified DataFrame with \"price\", \"area\", and \"rent\" columns cleaned and converted to float.\n",
    "    \"\"\"\n",
    "    \n",
    "    for var in [\"price\", \"area\", \"rent\"]:\n",
    "        \n",
    "        data[var] = (\n",
    "            data[var]\n",
    "            .astype(str)                              \n",
    "            .str.replace('[ a-zA-ZłŁ²]*', '', regex=True)\n",
    "            .str.replace(',', '.', regex=False)\n",
    "        )\n",
    "        \n",
    "        data[var] = pd.to_numeric(data[var])\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   price_before area_before rent_before      price   area    rent\n",
      "0    415 000 zł     37,4 m²     Zapytaj   415000.0  37.40     NaN\n",
      "1    880 000 zł     68,5 m²      750 zł   880000.0  68.50   750.0\n",
      "2    590 000 zł       60 m²        1 zł   590000.0  60.00     1.0\n",
      "3    699 000 zł       77 m²     Zapytaj   699000.0  77.00     NaN\n",
      "4  1 378 000 zł    69,03 m²    1 120 zł  1378000.0  69.03  1120.0\n"
     ]
    }
   ],
   "source": [
    "cleaned_numeric_columns_data = clean_numeric_columns(standardized_missing_values_data)\n",
    "\n",
    "clean_numeric_columns_show = pd.concat([data_initial[[\"price\", \"area\", \"rent\"]].head(),\n",
    "               cleaned_numeric_columns_data[[\"price\", \"area\", \"rent\"]].head()],\n",
    "              axis=1)\n",
    "\n",
    "clean_numeric_columns_show.columns = [\"price_before\", \"area_before\", \"rent_before\",\n",
    "                                      \"price\", \"area\", \"rent\"]\n",
    "print(clean_numeric_columns_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### categorize_rent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_rent(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Categorizes rental prices into discrete bins and creates a new column 'rent_cat'.\n",
    "\n",
    "    This function groups the values from the 'rent' column into five predefined ranges (bins)\n",
    "    to simplify analysis or modeling. Each bin is assigned a numeric label from 1 to 5.\n",
    "    The bins are: \n",
    "        - 0 to 500\n",
    "        - 501 to 1000\n",
    "        - 1001 to 1500\n",
    "        - 1501 to 2000\n",
    "        - 2001 and above\n",
    "\n",
    "    The original 'rent' column is removed after categorization, and the new 'rent_cat'\n",
    "    column is added with float-typed values.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The input DataFrame that contains a 'rent' column with numeric values.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The modified DataFrame with the 'rent' column replaced by a categorical 'rent_cat' column.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Group the values from the 'rent' column into ranges\n",
    "    data['rent_cat'] = pd.cut(data['rent'],\n",
    "                              bins = [0, 500, 1000, 1500, 2000, np.inf],\n",
    "                              labels = np.arange(1, 6, 1))\n",
    "    data['rent_cat'] = data['rent_cat'].astype(\"float\")\n",
    "    \n",
    "    # Drop original 'rent' column\n",
    "    data = data.drop('rent', axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  rent_before  rent_cat\n",
      "1      750 zł       2.0\n",
      "2        1 zł       1.0\n",
      "4    1 120 zł       3.0\n",
      "5      750 zł       2.0\n",
      "6      700 zł       2.0\n"
     ]
    }
   ],
   "source": [
    "categorized_rent_data = categorize_rent(cleaned_numeric_columns_data)\n",
    "\n",
    "categorize_rent_show = pd.concat([data_initial[[\"rent\"]].head(7),\n",
    "                                  categorized_rent_data[[\"rent_cat\"]].head(7)],\n",
    "                                 axis=1)\n",
    "\n",
    "categorize_rent_show.columns = [\"rent_before\", \"rent_cat\"]\n",
    "print(categorize_rent_show.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process_floor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_floor_data(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Process floor information in the dataset by extracting and standardizing floor-related features.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Extracts the total number of floors in the building from the 'floor' column.\n",
    "       - Assumes the format is 'apartment_floor/number_of_floors'.\n",
    "       - If the format does not contain '/', sets the value to NaN.\n",
    "    2. Extracts the apartment's floor number from the 'floor' column.\n",
    "       - Converts special floor names ('parter', 'suterena') to '0'.\n",
    "       - Replaces '> 10' with None (to handle inconsistent data).\n",
    "    3. If the apartment's floor is labeled as 'poddasze' (attic), replaces it with the total number of floors.\n",
    "    4. Converts the apartment floor and total floors columns to float type.\n",
    "    5. Removes the original 'floor' column from the dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    data : pandas.DataFrame\n",
    "        The input dataframe containing a 'floor' column with floor information.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The dataframe with two new columns:\n",
    "        - 'number_floor_in_building': total floors in the building as float.\n",
    "        - 'ap_floor': apartment floor number as float.\n",
    "        The original 'floor' column is dropped.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract apartment floor (left part before '/'), convert special names\n",
    "    data['number_floor_in_building'] = data['floor'].apply(lambda x: str(x).split('/')[1] if str(x).__contains__('/') else np.NaN).astype('float')\n",
    "    data['ap_floor'] = data['floor'].apply(lambda x: str(x).split('/')[0]).replace({'parter':'0',\n",
    "                                                                                    'suterena':'0',\n",
    "                                                                                    '> 10': None})\n",
    "    # Replace 'poddasze' (attic) with total floors in building\n",
    "    data['ap_floor'] = np.where(data['ap_floor'] == 'poddasze',\n",
    "                                        data['number_floor_in_building'], \n",
    "                                        data['ap_floor'])\n",
    "    # Convert apartment floor to float\n",
    "    data['ap_floor'] = pd.to_numeric(data['ap_floor'])\n",
    "    \n",
    "    # Drop original 'floor' column\n",
    "    data = data.drop('floor', axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      floor  ap_floor  number_floor_in_building\n",
      "0       1/3       1.0                       3.0\n",
      "1       4/7       4.0                       7.0\n",
      "2  parter/1       0.0                       1.0\n",
      "3    parter       0.0                       NaN\n",
      "4       3/4       3.0                       4.0\n"
     ]
    }
   ],
   "source": [
    "processed_floor_data = process_floor_data(categorized_rent_data)\n",
    "\n",
    "process_floor_data_show = pd.concat([data_initial[[\"floor\"]].head(),\n",
    "                                  processed_floor_data[[\"ap_floor\", \"number_floor_in_building\"]].head()],\n",
    "                                 axis=1)\n",
    "\n",
    "print(process_floor_data_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill_missing_categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_categoricals(data):\n",
    "    cols = ['ownership_status', 'flat_condition', 'heating', 'windows', 'mater', 'devel_type']\n",
    "    data[cols] = data[cols].fillna('nie podano')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          missing_count  missing_percent\n",
      "availability                      38287            81.84\n",
      "equipment                         32486            69.44\n",
      "rent_cat                          25514            54.54\n",
      "utilities                         21380            45.70\n",
      "parking                           20529            43.88\n",
      "add_inf                           19672            42.05\n",
      "security                          14992            32.05\n",
      "perks                             10959            23.43\n",
      "number_floor_in_building           2238             4.78\n",
      "price                              2109             4.51\n",
      "ap_floor                           1235             2.64\n",
      "year                                 26             0.06\n",
      "ad_type                               0             0.00\n",
      "market                                0             0.00\n",
      "devel_type                            0             0.00\n",
      "windows                               0             0.00\n",
      "lift                                  0             0.00\n",
      "heating                               0             0.00\n",
      "flat_condition                        0             0.00\n",
      "ownership_status                      0             0.00\n",
      "num_rooms                             0             0.00\n",
      "mater                                 0             0.00\n",
      "area                                  0             0.00\n",
      "address                               0             0.00\n",
      "link                                  0             0.00\n"
     ]
    }
   ],
   "source": [
    "fill_missing_categoricals_data = fill_missing_categoricals(processed_floor_data)\n",
    "\n",
    "missing_info = (\n",
    "    fill_missing_categoricals_data.isna()\n",
    "    .sum()\n",
    "    .to_frame(name='missing_count')\n",
    "    .assign(\n",
    "        missing_percent=lambda df: round(100 * df['missing_count'] / len(fill_missing_categoricals_data), 2)\n",
    "    )\n",
    "    .sort_values(by='missing_count', ascending=False)\n",
    ")\n",
    "\n",
    "print(missing_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encode_parking_presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_parking_presence(data):\n",
    "    data['parking_coded'] = data['parking'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    parking  parking_coded\n",
      "0  garaż/miejsce parkingowe              1\n",
      "1  garaż/miejsce parkingowe              1\n",
      "2  garaż/miejsce parkingowe              1\n",
      "3  garaż/miejsce parkingowe              1\n",
      "4                   Zapytaj              0\n",
      "5                   Zapytaj              0\n"
     ]
    }
   ],
   "source": [
    "encoded_parking_presence_data = encode_parking_presence(fill_missing_categoricals_data)\n",
    "\n",
    "encode_parking_presence_show = pd.concat([data_initial[[\"parking\"]].head(6),\n",
    "                                  encoded_parking_presence_data[[\"parking_coded\"]].head(6)],\n",
    "                                 axis=1)\n",
    "\n",
    "print(encode_parking_presence_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert_year_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_year_to_int(data):\n",
    "    data['year'] = data['year'].apply(lambda x: int(x) if isinstance(x, str) else x)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descrition before:\n",
      "count     46782\n",
      "unique      207\n",
      "top        2023\n",
      "freq       9691\n",
      "Name: year, dtype: object\n",
      "\n",
      "Descrition after:\n",
      "count    46756.000000\n",
      "mean      1998.217747\n",
      "std         83.953663\n",
      "min          1.000000\n",
      "25%       1983.000000\n",
      "50%       2020.000000\n",
      "75%       2023.000000\n",
      "max       2027.000000\n",
      "Name: year, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "converted_year_to_int_data = convert_year_to_int(encoded_parking_presence_data)\n",
    "print(\"Descrition before:\")\n",
    "print(data_initial['year'].describe())\n",
    "print()\n",
    "print(\"Descrition after:\")\n",
    "print(converted_year_to_int_data['year'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardize_ownership_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_ownership_labels(data):\n",
    "    data['ownership_status'] = data['ownership_status'].apply(\n",
    "        lambda x: 'spółdzielcze wł. prawo do lokalu' if x == 'spółdzielcze własnościowe' else x\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts before:\n",
      "ownership_status                 \n",
      "pełna własność                       36790\n",
      "Zapytaj                               8158\n",
      "spółdzielcze wł. prawo do lokalu      1576\n",
      "udział                                 171\n",
      "użytkowanie wieczyste / dzierżawa       86\n",
      "spółdzielcze własnościowe                1\n",
      "dtype: int64\n",
      "\n",
      "Value counts  after:\n",
      "ownership_status                 \n",
      "pełna własność                       36790\n",
      "nie podano                            8158\n",
      "spółdzielcze wł. prawo do lokalu      1577\n",
      "udział                                 171\n",
      "użytkowanie wieczyste / dzierżawa       86\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "standardized_ownership_labels_data = standardize_ownership_labels(converted_year_to_int_data)\n",
    "\n",
    "print(\"Value counts before:\")\n",
    "print(data_initial[['ownership_status']].value_counts())\n",
    "print()\n",
    "print(\"Value counts  after:\")\n",
    "print(standardized_ownership_labels_data[['ownership_status']].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple_choice_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utilities: ['telewizja kablowa', 'internet', 'telefon']\n",
      "security: ['drzwi / okna antywłamaniowe', 'teren zamknięty', 'domofon / wideofon', 'monitoring / ochrona', 'rolety antywłamaniowe', 'system alarmowy']\n",
      "equipment: ['zmywarka', 'lodówka', 'meble', 'piekarnik', 'kuchenka', 'pralka', 'telewizor']\n",
      "add_inf: ['pom. użytkowe', 'piwnica', 'dwupoziomowe', 'oddzielna kuchnia', 'klimatyzacja']\n",
      "perks: ['balkon', 'taras', 'ogródek']\n"
     ]
    }
   ],
   "source": [
    "def items_of_var(var, data = standardized_ownership_labels_data):   \n",
    "    item_list = []\n",
    "    for items in data[var]:\n",
    "        present = str(items).split(',')\n",
    "        present = [x.strip(' ') for x in present]\n",
    "        item_list.extend(present)\n",
    "\n",
    "    item_list = list(dict.fromkeys(item_list))\n",
    "    if 'nan' in item_list:\n",
    "        item_list.remove('nan')\n",
    "    return item_list\n",
    "\n",
    "perklist = items_of_var('perks')\n",
    "utilitylist = items_of_var('utilities')\n",
    "securitylist = items_of_var('security')\n",
    "equipmentlist = items_of_var('equipment')\n",
    "additionallist = items_of_var('add_inf')\n",
    "\n",
    "var_values_dict = {'utilities': utilitylist,\n",
    "                   'security': securitylist,\n",
    "                   'equipment': equipmentlist,\n",
    "                   'add_inf': additionallist,\n",
    "                   'perks': perklist}\n",
    "\n",
    "for var in var_values_dict:\n",
    "    print(f'{var}: {var_values_dict[var]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Data Preparation/multiple_choice_var_dict.joblib']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_values_dict_path = \"1. Data Preparation/multiple_choice_var_dict.joblib\"\n",
    "joblib.dump(var_values_dict, var_values_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitcolumn(serieslike, colname, items, missing_categories):\n",
    "    input_value = serieslike[colname]\n",
    "    \n",
    "    if pd.isna(input_value):\n",
    "        return pd.Series([0 for x in items])\n",
    "    \n",
    "    present = input_value.split(',')\n",
    "    present = [x.strip(' ') for x in present]\n",
    "    present = [x for x in present if len(x) > 1]\n",
    "    \n",
    "    presences = [1 if x in present else 0 for x in items]\n",
    "    \n",
    "    new_items = [x for x in present if x not in items]\n",
    "    if new_items:\n",
    "        missing_categories.extend(new_items)\n",
    "    \n",
    "    return pd.Series(presences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_choice_transform(data, train_dataset):\n",
    "    \n",
    "    var_values_dict = joblib.load(\"1. Data Preparation/multiple_choice_var_dict.joblib\")\n",
    "    \n",
    "    missing_categories = []\n",
    "    \n",
    "    for key in var_values_dict:\n",
    "        column_names = [key + '_' + x for x in var_values_dict[key]]\n",
    "        data[column_names] = data.apply(splitcolumn, args=(key, var_values_dict[key], missing_categories), axis=1)\n",
    "        \n",
    "    data = data.drop(var_values_dict, axis=1)\n",
    "    \n",
    "    if train_dataset:\n",
    "        if missing_categories:\n",
    "            category_counts = Counter(missing_categories)\n",
    "            print(\"There are new categories that are not in the dictionary:\")\n",
    "            for category, count in category_counts.items():\n",
    "                print(f\"  - {category}: {count} razy\")\n",
    "        else:\n",
    "            print(\"All the categorizations occurring in the set in multi-vector selection variables were coded.\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the categorizations occurring in the set in multi-vector selection variables were coded.\n",
      "                              utilities  utilities_telewizja kablowa  \\\n",
      "0  telewizja kablowa, internet, telefon                            1   \n",
      "1           telewizja kablowa, internet                            1   \n",
      "2           telewizja kablowa, internet                            1   \n",
      "3                              internet                            0   \n",
      "4  telewizja kablowa, internet, telefon                            1   \n",
      "5  telewizja kablowa, internet, telefon                            1   \n",
      "\n",
      "                                            security  \\\n",
      "0  drzwi / okna antywłamaniowe, teren zamknięty, ...   \n",
      "1  drzwi / okna antywłamaniowe, teren zamknięty, ...   \n",
      "2                teren zamknięty, domofon / wideofon   \n",
      "3  drzwi / okna antywłamaniowe, teren zamknięty, ...   \n",
      "4  drzwi / okna antywłamaniowe, domofon / wideofo...   \n",
      "5                                 domofon / wideofon   \n",
      "\n",
      "   security_domofon / wideofon  \\\n",
      "0                            1   \n",
      "1                            1   \n",
      "2                            1   \n",
      "3                            1   \n",
      "4                            1   \n",
      "5                            1   \n",
      "\n",
      "                                           equipment  equipment_zmywarka  \\\n",
      "0                                    brak informacji                   0   \n",
      "1  zmywarka, lodówka, meble, piekarnik, kuchenka,...                   1   \n",
      "2                                    brak informacji                   0   \n",
      "3                                    brak informacji                   0   \n",
      "4             zmywarka, lodówka, piekarnik, kuchenka                   1   \n",
      "5                                              meble                   0   \n",
      "\n",
      "           add_inf  add_inf_piwnica          perks  perks_balkon  \n",
      "0  brak informacji                0  balkon, taras             1  \n",
      "1    pom. użytkowe                0         balkon             1  \n",
      "2    pom. użytkowe                0        ogródek             0  \n",
      "3  brak informacji                0        ogródek             0  \n",
      "4          piwnica                1         balkon             1  \n",
      "5          piwnica                1         balkon             1  \n"
     ]
    }
   ],
   "source": [
    "multiple_choice_transformed_data = multiple_choice_transform(standardized_ownership_labels_data, var_values_dict, train_dataset = True)\n",
    "\n",
    "vars_before = ['utilities', 'security', 'equipment', 'add_inf', 'perks']\n",
    "vars_after = ['utilities_telewizja kablowa', 'security_domofon / wideofon',\n",
    "              'equipment_zmywarka', 'add_inf_piwnica', 'perks_balkon']\n",
    "\n",
    "multiple_choice_transform_show = pd.concat([data_initial[vars_before].head(6),\n",
    "                                  multiple_choice_transformed_data[vars_after].head(6)],\n",
    "                                 axis=1)\n",
    "\n",
    "print(multiple_choice_transform_show[['utilities', 'utilities_telewizja kablowa',\n",
    "                                     'security', 'security_domofon / wideofon',\n",
    "                                     'equipment', 'equipment_zmywarka',\n",
    "                                     'add_inf', 'add_inf_piwnica',\n",
    "                                     'perks', 'perks_balkon']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### location_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def address_transform(addressline, cities_dict):\n",
    "    if pd.isna(addressline):\n",
    "        region = np.nan\n",
    "        location = np.nan\n",
    "        street = np.nan\n",
    "\n",
    "        return pd.Series([region, location, street])\n",
    "    \n",
    "    region = addressline.split(',')[-1].strip(' ')\n",
    "    city_in_region = cities_dict[region]\n",
    "        \n",
    "    if addressline.split(',')[-2].strip(' ') in city_in_region:\n",
    "        location = addressline.split(',')[-2].strip(' ')\n",
    "            \n",
    "    elif addressline.split(',')[-3].strip(' ') in city_in_region:\n",
    "        location = addressline.split(',')[-3].strip(' ')\n",
    "            \n",
    "    else:\n",
    "        location = np.nan\n",
    "\n",
    "    if addressline.split(',')[0].strip(' ') == location:\n",
    "        street = np.nan\n",
    "            \n",
    "    else:\n",
    "        street = addressline.split(',')[0].strip(' ')\n",
    "        street = street.removeprefix('ul. ')\n",
    "        street = street.removeprefix('al. ')\n",
    "        street = street.removeprefix('pl. ')\n",
    "        street = street.strip(' ')\n",
    "\n",
    "    return pd.Series([region, location, street])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_transform(data):\n",
    "    \n",
    "    locations = pd.read_csv('1. Data Preparation/locations_and_regions.csv')\n",
    "    \n",
    "    # Przetwarzanie danych o miejscowościach w Polsce na słownik województwo-miejscowości\n",
    "    # służący do przypisywania miejscowości adresom\n",
    "    locations = locations[locations['Rodzaj'].isin(['wieś','miasto','osada','kolonia','osada leśna'])]\n",
    "    locations = locations.groupby('Województwo',axis=0)\n",
    "\n",
    "    cities_dict = {}\n",
    "    for reg in locations:\n",
    "        cities_dict[reg[0]] = list(reg[1]['Nazwa miejscowości'])\n",
    "    cities_dict['zachodniopomorskie'].append('Stargard')\n",
    "    \n",
    "    \n",
    " \n",
    "    data[['region', 'location', 'street/district']] = data['address'].apply(address_transform, args = [cities_dict])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46782 entries, 0 to 46781\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   address          46782 non-null  object\n",
      " 1   region           46782 non-null  object\n",
      " 2   location         46726 non-null  object\n",
      " 3   street/district  41415 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>region</th>\n",
       "      <th>location</th>\n",
       "      <th>street/district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ul. Henryka Strobanda, Wrzosy, Toruń, kujawsko...</td>\n",
       "      <td>kujawsko-pomorskie</td>\n",
       "      <td>Toruń</td>\n",
       "      <td>Henryka Strobanda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>łąkowa 27 B, Stare Polesie, Polesie, Łódź, łód...</td>\n",
       "      <td>łódzkie</td>\n",
       "      <td>Łódź</td>\n",
       "      <td>łąkowa 27 B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ul. Błękitna, Marki, wołomiński, mazowieckie</td>\n",
       "      <td>mazowieckie</td>\n",
       "      <td>Marki</td>\n",
       "      <td>Błękitna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Szyce, Wielka Wieś, krakowski, małopolskie</td>\n",
       "      <td>małopolskie</td>\n",
       "      <td>Wielka Wieś</td>\n",
       "      <td>Szyce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ul. Rakowiecka 43A, Stary Mokotów, Mokotów, Wa...</td>\n",
       "      <td>mazowieckie</td>\n",
       "      <td>Warszawa</td>\n",
       "      <td>Rakowiecka 43A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             address              region  \\\n",
       "0  ul. Henryka Strobanda, Wrzosy, Toruń, kujawsko...  kujawsko-pomorskie   \n",
       "1  łąkowa 27 B, Stare Polesie, Polesie, Łódź, łód...             łódzkie   \n",
       "2       ul. Błękitna, Marki, wołomiński, mazowieckie         mazowieckie   \n",
       "3         Szyce, Wielka Wieś, krakowski, małopolskie         małopolskie   \n",
       "4  ul. Rakowiecka 43A, Stary Mokotów, Mokotów, Wa...         mazowieckie   \n",
       "\n",
       "      location    street/district  \n",
       "0        Toruń  Henryka Strobanda  \n",
       "1         Łódź        łąkowa 27 B  \n",
       "2        Marki           Błękitna  \n",
       "3  Wielka Wieś              Szyce  \n",
       "4     Warszawa     Rakowiecka 43A  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_transformed_data = location_transform(multiple_choice_transformed_data)\n",
    "\n",
    "location_transform_var = ['address', 'region', 'location', 'street/district']\n",
    "\n",
    "print(location_transformed_data[location_transform_var].info())\n",
    "location_transformed_data[location_transform_var].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### city_info_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_info_transform (data):\n",
    "        \n",
    "    locations_data = pd.read_excel(\"1. Data Preparation/locations_info.xlsx\")\n",
    "    \n",
    "    locations_data['pop_numb_cat'] = pd.cut(locations_data['Liczba ludności'],\n",
    "                                          bins = [0,10000,20000,50000,100000,\n",
    "                                                  250000,500000,1000000,2000000],\n",
    "                                          labels = np.arange(1,9,1))\n",
    "    \n",
    "    locations_data['pop_dens_cat'] = pd.cut(locations_data['Gęstość zaludnienia'], bins = range(0,4001,500),\n",
    "                                      labels = np.arange(0,8,1))\n",
    "    \n",
    "    data_merged = data.loc[:,'link':'street/district'].merge(locations_data,\n",
    "                                                             left_on=['location', 'region'],\n",
    "                                                             right_on=['Miasto', 'Województwo'],\n",
    "                                                             how='left')\n",
    "\n",
    "    data_merged['with_powiat_rights'] = data_merged['na_prawach_powiatu'].fillna(0)\n",
    "\n",
    "    data_merged['pop_numb_cat'] = pd.to_numeric(data_merged['pop_numb_cat'])\n",
    "    data_merged['pop_dens_cat'] = pd.to_numeric(data_merged['pop_dens_cat'])\n",
    "\n",
    "    data_merged['pop_numb_cat'].fillna(0, inplace = True)\n",
    "    data_merged['pop_dens_cat'].fillna(0, inplace = True)\n",
    "    \n",
    "    data_merged.drop(['Miasto', 'Powiat', 'Województwo', 'Powierzchnia',\n",
    "                      'Liczba ludności','Gęstość zaludnienia','na_prawach_powiatu'],\n",
    "                     axis=1, inplace = True)\n",
    "    \n",
    "    return data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>region</th>\n",
       "      <th>location</th>\n",
       "      <th>street/district</th>\n",
       "      <th>with_powiat_rights</th>\n",
       "      <th>pop_numb_cat</th>\n",
       "      <th>pop_dens_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ul. Henryka Strobanda, Wrzosy, Toruń, kujawsko...</td>\n",
       "      <td>kujawsko-pomorskie</td>\n",
       "      <td>Toruń</td>\n",
       "      <td>Henryka Strobanda</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>łąkowa 27 B, Stare Polesie, Polesie, Łódź, łód...</td>\n",
       "      <td>łódzkie</td>\n",
       "      <td>Łódź</td>\n",
       "      <td>łąkowa 27 B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ul. Błękitna, Marki, wołomiński, mazowieckie</td>\n",
       "      <td>mazowieckie</td>\n",
       "      <td>Marki</td>\n",
       "      <td>Błękitna</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Szyce, Wielka Wieś, krakowski, małopolskie</td>\n",
       "      <td>małopolskie</td>\n",
       "      <td>Wielka Wieś</td>\n",
       "      <td>Szyce</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ul. Rakowiecka 43A, Stary Mokotów, Mokotów, Wa...</td>\n",
       "      <td>Warszawa</td>\n",
       "      <td>Warszawa</td>\n",
       "      <td>Rakowiecka 43A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             address              region  \\\n",
       "0  ul. Henryka Strobanda, Wrzosy, Toruń, kujawsko...  kujawsko-pomorskie   \n",
       "1  łąkowa 27 B, Stare Polesie, Polesie, Łódź, łód...             łódzkie   \n",
       "2       ul. Błękitna, Marki, wołomiński, mazowieckie         mazowieckie   \n",
       "3         Szyce, Wielka Wieś, krakowski, małopolskie         małopolskie   \n",
       "4  ul. Rakowiecka 43A, Stary Mokotów, Mokotów, Wa...            Warszawa   \n",
       "\n",
       "      location    street/district  with_powiat_rights  pop_numb_cat  \\\n",
       "0        Toruń  Henryka Strobanda                 1.0           5.0   \n",
       "1         Łódź        łąkowa 27 B                 1.0           7.0   \n",
       "2        Marki           Błękitna                 0.0           3.0   \n",
       "3  Wielka Wieś              Szyce                 0.0           0.0   \n",
       "4     Warszawa     Rakowiecka 43A                 1.0           8.0   \n",
       "\n",
       "   pop_dens_cat  \n",
       "0           3.0  \n",
       "1           4.0  \n",
       "2           2.0  \n",
       "3           0.0  \n",
       "4           6.0  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_info_transformed_data = city_info_transform(location_transformed_data)\n",
    "location_transform_var = ['address', 'region','location','street/district',\n",
    "                          'with_powiat_rights', 'pop_numb_cat',\n",
    "                          'pop_dens_cat']\n",
    "city_info_transformed_data[location_transform_var].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preliminary_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preliminary_transform (data, train_dataset):\n",
    "    standardized_missing_values_data = standardize_missing_values(data)\n",
    "    cleaned_numeric_columns_data = clean_numeric_columns(standardized_missing_values_data)\n",
    "    categorized_rent_data = categorize_rent(cleaned_numeric_columns_data)\n",
    "    processed_floor_data = process_floor_data(categorized_rent_data)\n",
    "    fill_missing_categoricals_data = fill_missing_categoricals(processed_floor_data)\n",
    "    encoded_parking_presence_data = encode_parking_presence(fill_missing_categoricals_data)\n",
    "    converted_year_to_int_data = convert_year_to_int(encoded_parking_presence_data)\n",
    "    standardized_ownership_labels_data = standardize_ownership_labels(converted_year_to_int_data)\n",
    "    multiple_choice_transformed_data = multiple_choice_transform(standardized_ownership_labels_data,\n",
    "                                                                 train_dataset)\n",
    "    location_transformed_data = location_transform(multiple_choice_transformed_data)\n",
    "    city_info_transformed_data = city_info_transform(location_transformed_data)\n",
    "    return city_info_transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the categorizations occurring in the set in multi-vector selection variables were coded.\n"
     ]
    }
   ],
   "source": [
    "preliminary_transformed_data = preliminary_transform(data_initial, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 46782 entries, 0 to 46781\n",
      "Data columns (total 51 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   link                                  46782 non-null  object \n",
      " 1   price                                 44673 non-null  float64\n",
      " 2   address                               46782 non-null  object \n",
      " 3   area                                  46782 non-null  float64\n",
      " 4   num_rooms                             46782 non-null  int64  \n",
      " 5   ownership_status                      46782 non-null  object \n",
      " 6   flat_condition                        46782 non-null  object \n",
      " 7   parking                               26253 non-null  object \n",
      " 8   heating                               46782 non-null  object \n",
      " 9   market                                46782 non-null  object \n",
      " 10  ad_type                               46782 non-null  object \n",
      " 11  availability                          8495 non-null   object \n",
      " 12  year                                  46756 non-null  float64\n",
      " 13  devel_type                            46782 non-null  object \n",
      " 14  windows                               46782 non-null  object \n",
      " 15  lift                                  46782 non-null  object \n",
      " 16  mater                                 46782 non-null  object \n",
      " 17  rent_cat                              21268 non-null  float64\n",
      " 18  number_floor_in_building              44544 non-null  float64\n",
      " 19  ap_floor                              45547 non-null  float64\n",
      " 20  parking_coded                         46782 non-null  int64  \n",
      " 21  utilities_telewizja kablowa           46782 non-null  int64  \n",
      " 22  utilities_internet                    46782 non-null  int64  \n",
      " 23  utilities_telefon                     46782 non-null  int64  \n",
      " 24  security_drzwi / okna antywłamaniowe  46782 non-null  int64  \n",
      " 25  security_teren zamknięty              46782 non-null  int64  \n",
      " 26  security_domofon / wideofon           46782 non-null  int64  \n",
      " 27  security_monitoring / ochrona         46782 non-null  int64  \n",
      " 28  security_rolety antywłamaniowe        46782 non-null  int64  \n",
      " 29  security_system alarmowy              46782 non-null  int64  \n",
      " 30  equipment_zmywarka                    46782 non-null  int64  \n",
      " 31  equipment_lodówka                     46782 non-null  int64  \n",
      " 32  equipment_meble                       46782 non-null  int64  \n",
      " 33  equipment_piekarnik                   46782 non-null  int64  \n",
      " 34  equipment_kuchenka                    46782 non-null  int64  \n",
      " 35  equipment_pralka                      46782 non-null  int64  \n",
      " 36  equipment_telewizor                   46782 non-null  int64  \n",
      " 37  add_inf_pom. użytkowe                 46782 non-null  int64  \n",
      " 38  add_inf_piwnica                       46782 non-null  int64  \n",
      " 39  add_inf_dwupoziomowe                  46782 non-null  int64  \n",
      " 40  add_inf_oddzielna kuchnia             46782 non-null  int64  \n",
      " 41  add_inf_klimatyzacja                  46782 non-null  int64  \n",
      " 42  perks_balkon                          46782 non-null  int64  \n",
      " 43  perks_taras                           46782 non-null  int64  \n",
      " 44  perks_ogródek                         46782 non-null  int64  \n",
      " 45  region                                46782 non-null  object \n",
      " 46  location                              46726 non-null  object \n",
      " 47  street/district                       41415 non-null  object \n",
      " 48  pop_numb_cat                          46782 non-null  float64\n",
      " 49  pop_dens_cat                          46782 non-null  float64\n",
      " 50  with_powiat_rights                    46782 non-null  float64\n",
      "dtypes: float64(9), int64(26), object(16)\n",
      "memory usage: 18.6+ MB\n"
     ]
    }
   ],
   "source": [
    "preliminary_transformed_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing and outlier observations\n",
    "Analysis of missing and outlier observations was conducted in the file: **missvalue_outliers_analysis** <br>\n",
    "The file shows the distributions of each variable, establishes the variables taken into the model, and sets limits beyond which an observation will be considered an outlier. <br><br>\n",
    "\n",
    "In summary, the model wiil be trained on the data of apartments which:<br>\n",
    "1. price is in the range of 100 thousand PLN to 1 million PLN\n",
    "2. area is in the range of 20 m² to 150 m²\n",
    "3. is in a building that has less than 20 floors\n",
    "4. is in a building that was built no earlier than 1900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables were **excluded** from further analysis:\n",
    "1. link\n",
    "2. availability\n",
    "3. street/distric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, in some categorical variables, categories that occurred less frequently than 5% of the set were converted to “other” (\"inny\" in Polish) categories. These were the variables:\n",
    "1. **ownership_status** - 'spółdzielcze wł. prawo do lokalu', 'udział', 'użytkowanie wieczyste / dzierżawa'\n",
    "2. **heating** - 'kotłownia', 'elektryczne', 'piece kaflowe'\n",
    "3. **devel_type** - 'plomba', 'loft', 'dom wolnostojący', 'szeregowiec'\n",
    "4. **windows** - 'drewniane', 'aluminiowe'\n",
    "5. **mater** - 'drewno', 'keramzyt', 'beton', 'beton komórkowy', 'żelbet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_values = {\"max_floor\": 20,\n",
    "                  \"min_price\": 100000,\n",
    "                  \"max_price\": 1000000,\n",
    "                  \"min_area\": 20,\n",
    "                  \"max_area\": 150,\n",
    "                  \"min_year\": 1900,\n",
    "                  \"categories_to_replace\": ['spółdzielcze wł. prawo do lokalu', 'udział', 'użytkowanie wieczyste / dzierżawa',\n",
    "                                            'kotłownia', 'elektryczne', 'piece kaflowe',\n",
    "                                            'plomba', 'loft', 'dom wolnostojący', 'szeregowiec',\n",
    "                                            'drewniane', 'aluminiowe',\n",
    "                                            'drewno', 'keramzyt', 'beton', 'beton komórkowy', 'żelbet',\n",
    "                                            'inne', 'inny']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_drop(data, train_dataset,\n",
    "                 maxfloor,\n",
    "                 minprice, maxprice,\n",
    "                 minarea, maxarea,\n",
    "                 minyear, categories_to_replace):\n",
    "\n",
    "    data = data.replace(categories_to_replace, 'other')\n",
    "    \n",
    "    data_clean = data[data['price'] <= maxprice]\n",
    "    data_clean = data_clean[data_clean['price'] >= minprice]\n",
    "    \n",
    "    data_clean = data_clean[data_clean['area'] <= maxarea]\n",
    "    data_clean = data_clean[data_clean['area'] >= minarea]\n",
    "    \n",
    "    data_clean = data_clean[(data_clean['number_floor_in_building'] <= maxfloor)|(data_clean['number_floor_in_building'].isna())]\n",
    "    data_clean = data_clean[(data_clean['ap_floor'] <= maxfloor)|(data_clean['ap_floor'].isna())]\n",
    "    \n",
    "    data_clean['year'] = data_clean['year'].apply(lambda x: x if x >= minyear else np.nan)\n",
    "    \n",
    "    if train_dataset:\n",
    "        return data_clean\n",
    "    else:\n",
    "        if len(data) > (len(data_clean) + sum(data['price'].isna())):\n",
    "            print(\"\"\"\n",
    "                  W zbiorze wystąpiły obserwację o skrajnych wartościach\n",
    "                  ze względu na cenę, powierzchnię, piętro lub rok budynku.\n",
    "                  Może zmniejszeć dokładność prognozy\n",
    "                  \"\"\")\n",
    "        return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
